import requests
import json
from openai import OpenAI

openai_key = ""  # ì‹¤ì œ í‚¤ë¡œ êµì²´
client = OpenAI(api_key=openai_key)

MCP_SERVERS = {
    "weather": "http://localhost:8001",
    "news": "http://localhost:8002"
}

def fetch_tool_metadata():
    tools = []
    for name, base_url in MCP_SERVERS.items():
        try:
            res = requests.get(f"{base_url}/tools")
            for tool in res.json():
                tools.append({"mcp": name, "tool": tool})
        except Exception as e:
            print(f"[ERROR] {name} ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
    return tools

def ask_gpt_for_tool(user_input, tool_metadata):
    prompt = f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ì•„ë˜ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ MCP íˆ´ ëª©ë¡ì…ë‹ˆë‹¤:
{json.dumps(tool_metadata, indent=2, ensure_ascii=False)}

ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì— ì ì ˆí•œ MCP Toolì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ê³ , ìˆë‹¤ë©´ ì–´ë–¤ Toolì´ê³  ì–´ë–¤ íŒŒë¼ë¯¸í„°ë¥¼ ë„˜ê²¨ì•¼ í•˜ëŠ”ì§€ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì‘ë‹µ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤:

1. ì‚¬ìš©ìì˜ ìš”ì²­ì— ì ì ˆí•œ Toolì´ ì¡´ì¬í•˜ê³ , íŒŒë¼ë¯¸í„°ë„ ì¶©ë¶„íˆ ì£¼ì–´ì§„ ê²½ìš°:
{{
  "mcp": "<mcp ì´ë¦„>",
  "tool_name": "<tool ì´ë¦„>",
  "arguments": {{ <íŒŒë¼ë¯¸í„° í‚¤:ê°’> }},
  "route": "TOOL"
}}

2. MCP Tool ëª©ë¡ ì¤‘ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” Toolì´ ì—†ê±°ë‚˜, í•„ìš”í•œ íŒŒë¼ë¯¸í„°ê°€ ë¶€ì¡±í•˜ì—¬ í˜¸ì¶œì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°:
{{
  "route": "DIRECT"
}}

ì‘ë‹µì€ ë°˜ë“œì‹œ ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSON í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”. (ì˜ˆ: ```json ê°™ì€ í¬ë§· ì—†ì´)
"""
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )
    return json.loads(res.choices[0].message.content)

def call_mcp(mcp_name, tool_name, args):
    try:
        url = f"{MCP_SERVERS[mcp_name]}/tool/{tool_name}"
        with requests.post(url, json=args, stream=True) as res:
            for chunk in res.iter_content(chunk_size=None):
                if chunk:
                    print(chunk.decode(), end="", flush=True)
            print()
            return ""
    except Exception as e:
        return f"[ERROR] MCP í˜¸ì¶œ ì‹¤íŒ¨: {e}"

def main():
    tool_metadata = fetch_tool_metadata()
    print("\nâœ… MCP í´ë¼ì´ì–¸íŠ¸ ì‹œì‘")

    while True:
        user_input = input("\nğŸ’¬ ì‚¬ìš©ì ì…ë ¥ (exit ì¢…ë£Œ): ")
        if user_input.lower() == "exit":
            break

        decision = ask_gpt_for_tool(user_input, tool_metadata)

        if decision.get("route") == "DIRECT":

            def direct_stream():
                prompt = user_input
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    stream=True
                )
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        yield chunk.choices[0].delta.content

            print("ğŸ¤– ì§ì ‘ ì‘ë‹µ: ", end="", flush=True)
            for token in direct_stream():
                print(token, end="", flush=True)
            print()

        else:
            mcp = decision["mcp"]
            tool = decision["tool_name"]
            args = decision["arguments"]
            call_mcp(mcp, tool, args)

if __name__ == "__main__":
    main()

