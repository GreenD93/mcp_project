import requests
import json
from openai import OpenAI

openai_key = ""  # ì‹¤ì œ í‚¤ë¡œ êµì²´
client = OpenAI(api_key=openai_key)

MCP_SERVERS = {
    "weather": "http://localhost:8001",
    "news": "http://localhost:8002"
}

def fetch_tool_metadata():
    tools = []
    for name, base_url in MCP_SERVERS.items():
        try:
            res = requests.get(f"{base_url}/tools")
            for tool in res.json():
                tools.append({"mcp": name, "tool": tool})
        except Exception as e:
            print(f"[ERROR] {name} ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
    return tools

def ask_gpt_for_tool(user_input, tool_metadata):
    prompt = f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ì•„ë˜ëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ MCP íˆ´ì…ë‹ˆë‹¤:
{json.dumps(tool_metadata, indent=2, ensure_ascii=False)}

The result should be a plain json format, without code block formatting (like ```json).

ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì–´ë–¤ MCPë¥¼ ì‚¬ìš©í• ì§€ íŒë‹¨í•˜ê³ , í•´ë‹¹ MCP toolì— ì „ë‹¬í•  íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{{
  "mcp": "<mcp ì´ë¦„>",
  "tool_name": "<tool ì´ë¦„>",
  "arguments": {{ <íŒŒë¼ë¯¸í„° í‚¤:ê°’> }},
  "route": "TOOL"
}}
v
í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ë‹¤ìŒì²˜ëŸ¼:
{{
  "route": "DIRECT"
}}
"""
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )
    return json.loads(res.choices[0].message.content)

def call_mcp(mcp_name, tool_name, args):
    try:
        url = f"{MCP_SERVERS[mcp_name]}/tool/{tool_name}"
        with requests.post(url, json=args, stream=True) as res:
            for chunk in res.iter_content(chunk_size=None):
                if chunk:
                    print(chunk.decode(), end="", flush=True)
            print()
            return ""
    except Exception as e:
        return f"[ERROR] MCP í˜¸ì¶œ ì‹¤íŒ¨: {e}"

def main():
    tool_metadata = fetch_tool_metadata()
    print("\nâœ… MCP í´ë¼ì´ì–¸íŠ¸ ì‹œì‘")

    while True:
        user_input = input("\nğŸ’¬ ì‚¬ìš©ì ì…ë ¥ (exit ì¢…ë£Œ): ")
        if user_input.lower() == "exit":
            break

        decision = ask_gpt_for_tool(user_input, tool_metadata)

        if decision.get("route") == "DIRECT":

            def direct_stream():
                prompt = user_input
                response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    stream=True
                )
                for chunk in response:
                    if chunk.choices[0].delta.content:
                        yield chunk.choices[0].delta.content

            print("ğŸ¤– ì§ì ‘ ì‘ë‹µ: ", end="", flush=True)
            for token in direct_stream():
                print(token, end="", flush=True)
            print()

        else:
            mcp = decision["mcp"]
            tool = decision["tool_name"]
            args = decision["arguments"]
            call_mcp(mcp, tool, args)

if __name__ == "__main__":
    main()

